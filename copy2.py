# -*- coding: utf-8 -*-
"""copy2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yG8VntNjPRQpQXpfyJAFwNNMbzbx82tj
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

from google.colab import drive
drive.mount('/content/drive')

import warnings
warnings.filterwarnings('ignore')

import zipfile
with zipfile.ZipFile('/content/drive/MyDrive/credit_card.zip', 'r') as zip_ref:
    zip_ref.extractall('./')

df = pd.read_csv('creditcard.csv')

"""# 1. Display Top 5 Rows of The Dataset"""

df.head()

"""# 2. Display Last 5 Rows of The Dataset"""

df.tail()

"""# 3. Find Shape of Our Dataset (Number of Rows And Number of Columns)"""

df.shape

print("Number of Rows",df.shape[0])
print("Number of Columns",df.shape[1])

"""# 4. Get Information About Our Dataset Like Total Number of Rows, Total Number of Columns, Datatypes of Each Column And Memory Requirement"""

df.info()

"""# 5. Check Null Values In The Dataset"""

df.isnull().sum()

"""# Feature Scaling

Without scaling, the 'Amount' feature, which likely has a larger range, could dominate the learning process, leading to biased model predictions.
"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
df['Amount']=sc.fit_transform(pd.DataFrame(df['Amount']))

df.head()

df.duplicated().any()

"""# Remove Duplicated Values

Machine learning models can become biased if trained on duplicated data, as the duplicates can disproportionately influence the modelâ€™s learning process
"""

df = df.drop_duplicates()

df.shape

284807- 275663

"""# 6. Not Handling Imbalanced"""

count_classes = df['Class'].value_counts()
count_classes

import seaborn as sns

#Visualize the number of classes

LABELS = ["Normal", "Fraud"]
count_classes.plot(kind = 'bar', rot=0)

plt.title("Transaction Class Distribution")

plt.xticks(range(2), LABELS)

plt.xlabel("Class")

plt.ylabel("Frequency")

"""# 7. Store Feature Matrix In X And Response (Target) In Vector y"""

X = df.drop('Class',axis=1)
y = df['Class']

"""# 8. Splitting The Dataset Into The Training Set And Test Set"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,
                                                 random_state=42)

"""# 9. Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(X_train,y_train)

y_pred = rf.predict(X_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

accuracy_score(y_test,y_pred)

precision_score(y_test,y_pred)

recall_score(y_test,y_pred)

f1_score(y_test,y_pred)

"""# 10. Handling Imbalanced Dataset

# Undersampling
"""

normal = df[df['Class']==0]
fraud = df[df['Class']==1]

normal.shape

fraud.shape

normal_sample=normal.sample(n=473)

normal_sample.shape

new_data = pd.concat([normal_sample,fraud],ignore_index=True)

new_data['Class'].value_counts()

new_data.head()

X = new_data.drop('Class',axis=1)
y = new_data['Class']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,
                                                 random_state=42)

"""# 11. Random Forest Classifier with undersampled data"""

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(X_train,y_train)

y_pred2 = rf.predict(X_test)

accuracy_score(y_test,y_pred2)

precision_score(y_test,y_pred2)

recall_score(y_test,y_pred2)

f1_score(y_test,y_pred2)

"""# Oversampling"""

X = df.drop('Class',axis=1)
y = df['Class']

X.shape

y.shape

from imblearn.over_sampling import SMOTE

X_res,y_res = SMOTE().fit_resample(X,y)

y_res.value_counts()

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X_res,y_res,test_size=0.20,
                                                 random_state=42)

"""# 12. Random Forest Classifier with oversampled data"""

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(X_train,y_train)

y_pred3 = rf.predict(X_test)

accuracy_score(y_test,y_pred3)

precision_score(y_test,y_pred3)

recall_score(y_test,y_pred3)

f1_score(y_test,y_pred3)

"""# Save The Model"""

rf1 = RandomForestClassifier()
rf1.fit(X_res,y_res)

import joblib

joblib.dump(rf,"credit_card_model.pkl")

model = joblib.load("credit_card_model.pkl")

pred = model.predict([[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]])

if pred == 0:
    print("Normal Transaction")
else:
    print("Fraudulent Transaction")

#copied from original dataset
pred2 = model.predict([[472,-3.0435406239976,-3.15730712090228,1.08846277997285,2.2886436183814,1.35980512966107,-1.06482252298131,0.325574266158614,-0.0677936531906277,-0.270952836226548,-0.838586564582682,-0.414575448285725,-0.503140859566824,0.676501544635863,-1.69202893305906,2.00063483909015,0.666779695901966,0.599717413841732,1.72532100745514,0.283344830149495,2.10233879259444,0.661695924845707,0.435477208966341,1.37596574254306,-0.293803152734021,0.279798031841214,-0.145361714815161,-0.252773122530705,0.0357642251788156,529]])

if pred2 == 0:
    print("Normal Transaction")
else:
    print("Fraudulent Transaction")